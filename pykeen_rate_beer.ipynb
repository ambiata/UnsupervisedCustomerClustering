{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Customer Segmentation of \"Rate Beer\" using Knowledge Graph Embeddings\n",
    "This notebook uses Pytorch to create a Knowledge Graph Embedding of the customers purchases, usually data scientists try to segment customers in sequences like this using LSTM neural networks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.rate_beer_loader import RateBeerLoaderPykeen\n",
    "from pykeen.metrics.ranking import InverseHarmonicMeanRank\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.models import TransE\n",
    "from pykeen.evaluation.rank_based_evaluator import RankBasedEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the `RateBeerLoaderPykeen` object the `ratebeer.txt` file is read and creates a triples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a previous save\n",
      "Loading Triples from the path downloaded.\n"
     ]
    }
   ],
   "source": [
    "pykeen_rate_beer = RateBeerLoaderPykeen(\"ratebeer.txt\", checkpoint_name=\"torch_pipeline_checkpoints.pt\", limit_reviews_per_reviewer=500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_input = pykeen_rate_beer.get_rate_beer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now all the training input data is within `training_input`.\n",
    "We want a trained network embedding but we also want to be able to have scores as to the value of the graph.\n",
    "The paper uses a list of"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_transe, test_transe, vali_transe = training_input.split([0.90, 0.05, 0.05], random_state=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:=> no training loop checkpoint file found at '/home/sora4222/.data/pykeen/checkpoints/torch_pipeline_checkpoints_gamma_0.99.pt'. Creating a new file.\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: /home/sora4222/.data/pykeen/checkpoints/best-model-weights-580921d9-10ab-48da-b5c0-2d4c219f9ab0.pt\n",
      "INFO:pykeen.training.training_loop:=> no checkpoint found at '/home/sora4222/.data/pykeen/checkpoints/torch_pipeline_checkpoints_gamma_0.99.pt'. Creating a new file.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training epochs on cuda:0:   0%|          | 0/500 [00:00<?, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4318832c9dfe44a98844297169266148"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cuda:0:   0%|          | 0/31667 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b51f3f035c3c459481ea508eedcfc3d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for gamma_val in [0.99, 0.9, 0.8]:\n",
    "    transe_model_pipeline_results = pipeline(training=train_transe,\n",
    "                                             testing=test_transe, random_seed=100,\n",
    "                                             validation=vali_transe,\n",
    "                                             training_loop='sLCWA',\n",
    "                                             model=TransE,\n",
    "                                             model_kwargs={\"embedding_dim\": 50},\n",
    "                                             training_kwargs=dict(checkpoint_name=f\"torch_pipeline_checkpoints_gamma_{gamma_val}.pt\",\n",
    "                                                                  checkpoint_frequency=4, num_epochs=500),\n",
    "                                             stopper=\"early\",\n",
    "                                             stopper_kwargs=dict(frequency=1, patience=2, relative_delta=0.001),\n",
    "                                             lr_scheduler=\"CosineAnnealingLR\", lr_scheduler_kwargs=dict(T_max=10),\n",
    "                                             evaluator=RankBasedEvaluator,\n",
    "                                             evaluator_kwargs=dict(metrics=[\"InverseHarmonicMeanRank\"], add_defaults=True))\n",
    "    transe_model_pipeline_results.save_to_directory(f\"transe_trained_gamma_val_{gamma_val}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
